name: feast_job1
engine: default_spark

scheduler:
  schedule_interval: '0 6 * * *'
  start_date: 2021-09-10 00:00

sources:
  - type: pandas
    dict:
      id: [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010]
      title: ["message.send", "user.login", "user.signup", "user.logout", "message.send", "user.login", "user.signup", "user.logout", "user.signup", "user.logout"]
      published: ["2021-09-10", "2021-09-11", "2021-09-12", "2021-09-13", "2021-09-14", "2021-09-15", "2021-09-16", "2021-09-17", "2021-09-18", "2021-09-19"]

  - type: pandas
    file:
      type: csv
      path: "{{ project_root }}/../data/pandas_df1.csv"
      args:
        index_col: 0

computes:
  - type: sql
    sql: |-
      SELECT id,
             SUM(CASE WHEN title="message.send" THEN 1 ELSE 0) send_message_amount,
             SUM(CASE WHEN title="user.signup" THEN 1 ELSE 0) signup_times,
             SUM(CASE WHEN title="user.login" THEN 1 ELSE 0) login_times,`
             SUM(CASE WHEN title="user.logout" THEN 1 ELSE 0) logout_times,
             "{{ ts }}" timestamp
      FROM (
        SELECT * FROM {{ source_0 }}
        UNION ALL
        SELECT * FROM {{ source_1 }}
      ) t
      GROUP BY title

sinks:
  - type: feature_view
    name: fview_1
    ttl: 3600
    ingest:
      select_sql: |-
        SELECT id /* entity: user_id */,
               send_message_amount as send_amount /* type: int */,
               login_times /* type: int */,
               logout_times /* type: int */
        FROM {{ compute_0 }}
      store_table: test_sink_table
    datasource:
      class_name: tests.mock.hive_source.HiveSource
      table: test_sink_table
      event_timestamp_column: id
