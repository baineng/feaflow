name: test_job1
engine: default_spark

scheduler:
  schedule_interval: '0 6 * * *'
  depends_on: test_job2
  start_date: 20190430
  catch_up: true
  retries: 1

sources:
  - type: query
    sql: >-
      SELECT id, title, actor, target
      FROM events
      WHERE pt_date="{{ ds }}"
    alias: daily_events

computes:
  - type: sql
    sql: >-
      SELECT actor.id, count(*) as daily_amount
      FROM daily_events
      GROUP BY actor.id

sinks:
  - type: redis
    host: 127.0.0.1
    port: 6380